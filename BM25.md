# BM25 baseline

This readme contains instructions for reproducing a BM25 run using pyserini for the TREC track on tip-of-the-tongue (ToT) 
retrieval. You can view [Guidelines](https://trec-tot.github.io/guidelines) for more details.

## Baseline

To run the BM25 baseline:
```
DATA_PATH= ## enter path to data ###
python bm25.py --index_name bm25 --index_path ./anserini_indicies \
               --data_path $DATA_PATH \
               --param_k1 1.0 --param_b 1.0 \
               --field text --splits train-2024 \
               --run ./runs/bm25/train.run --run_format trec_eval --run_id baseline_bm25 \
               --negatives_out ./bm25_negatives/train-negatives.json

python bm25.py --index_name bm25 --index_path ./anserini_indicies \
               --data_path $DATA_PATH \
               --param_k1 1.0 --param_b 1.0 \
               --field text --splits dev1-2024 \
               --run ./runs/bm25/dev1.run --run_format trec_eval --run_id baseline_bm25 \
               --negatives_out ./bm25_negatives/dev1-negatives.json


python bm25.py --index_name bm25 --index_path ./anserini_indicies \
               --data_path $DATA_PATH \
               --param_k1 1.0 --param_b 1.0 \
               --field text  --splits dev2-2024 \
               --run ./runs/bm25/dev2.run --run_format trec_eval --run_id baseline_bm25 \
               --negatives_out ./bm25_negatives/dev2-negatives.json

## (once test split is released)
python bm25.py --index_name bm25 --index_path ./anserini_indicies \
               --data_path $DATA_PATH \
               --param_k1 1.0 --param_b 1.0 \
               --field text  --splits test-2024 \
               --run ./runs/bm25/test.run --run_format trec_eval --run_id baseline_bm25 
``` 

You can evaluate either using pytrec_eval (included in the script above), or use `trec_eval`:

```
# train
trec_eval -m ndcg_cut.10,1000 -m recall.1000  -m recip_rank $DATA_PATH/train-2024/qrel.txt ./runs/bm25/train.run
    recip_rank            	all	0.0530
    recall_1000           	all	0.3400
    ndcg_cut_10           	all	0.0610
    ndcg_cut_1000         	all	0.0968


# dev1
trec_eval -m ndcg_cut.10,1000 -m recall.1000  -m recip_rank $DATA_PATH/dev1-2024/qrel.txt ./runs/bm25/dev1.run
    recip_rank            	all	0.0676
    recall_1000           	all	0.3400
    ndcg_cut_10           	all	0.0701
    ndcg_cut_1000         	all	0.1053

# dev2
trec_eval -m ndcg_cut.10,1000 -m recall.1000  -m recip_rank $DATA_PATH/dev2-2024/qrel.txt ./runs/bm25/dev2.run
    recip_rank            	all	0.0590
    recall_1000           	all	0.3600
    ndcg_cut_10           	all	0.0657
    ndcg_cut_1000         	all	0.1033

```